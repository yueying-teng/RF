{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ddate</th>\n",
       "      <th>security_code</th>\n",
       "      <th>時価総額</th>\n",
       "      <th>売上</th>\n",
       "      <th>営業利益</th>\n",
       "      <th>純利益</th>\n",
       "      <th>総資産</th>\n",
       "      <th>現金･現金同等物</th>\n",
       "      <th>有価証券</th>\n",
       "      <th>流動資産</th>\n",
       "      <th>...</th>\n",
       "      <th>営業資産</th>\n",
       "      <th>営業負債</th>\n",
       "      <th>有形固定</th>\n",
       "      <th>使用資産</th>\n",
       "      <th>ROIC</th>\n",
       "      <th>EY</th>\n",
       "      <th>MAGIC</th>\n",
       "      <th>ROIC2</th>\n",
       "      <th>EY2</th>\n",
       "      <th>MKTCAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>AAL</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14824.000</td>\n",
       "      <td>2368.000</td>\n",
       "      <td>1957.000</td>\n",
       "      <td>30616.000</td>\n",
       "      <td>1061.000</td>\n",
       "      <td>2344.000</td>\n",
       "      <td>8127.000</td>\n",
       "      <td>...</td>\n",
       "      <td>4722.000</td>\n",
       "      <td>-4027.000</td>\n",
       "      <td>11819.000</td>\n",
       "      <td>12514.000</td>\n",
       "      <td>0.189228</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.114236</td>\n",
       "      <td>0.401220</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>ABF</td>\n",
       "      <td>3385.8000</td>\n",
       "      <td>4406.000</td>\n",
       "      <td>327.000</td>\n",
       "      <td>138.000</td>\n",
       "      <td>3867.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>1133.000</td>\n",
       "      <td>2220.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1022.000</td>\n",
       "      <td>-735.000</td>\n",
       "      <td>1459.000</td>\n",
       "      <td>1746.000</td>\n",
       "      <td>0.187285</td>\n",
       "      <td>0.096580</td>\n",
       "      <td>0.265137</td>\n",
       "      <td>0.111833</td>\n",
       "      <td>0.092430</td>\n",
       "      <td>3385.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACL</td>\n",
       "      <td>121.9050</td>\n",
       "      <td>245.360</td>\n",
       "      <td>13.484</td>\n",
       "      <td>8.232</td>\n",
       "      <td>146.453</td>\n",
       "      <td>8.461</td>\n",
       "      <td>0.000</td>\n",
       "      <td>86.766</td>\n",
       "      <td>...</td>\n",
       "      <td>78.305</td>\n",
       "      <td>-54.935</td>\n",
       "      <td>9.342</td>\n",
       "      <td>32.712</td>\n",
       "      <td>0.412203</td>\n",
       "      <td>0.110611</td>\n",
       "      <td>0.481594</td>\n",
       "      <td>0.390139</td>\n",
       "      <td>0.092395</td>\n",
       "      <td>121.9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>ADB</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32.645</td>\n",
       "      <td>2.448</td>\n",
       "      <td>1.466</td>\n",
       "      <td>23.528</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.764</td>\n",
       "      <td>...</td>\n",
       "      <td>6.352</td>\n",
       "      <td>-5.785</td>\n",
       "      <td>16.087</td>\n",
       "      <td>16.654</td>\n",
       "      <td>0.146992</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.185581</td>\n",
       "      <td>0.528041</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>ADN</td>\n",
       "      <td>846.9825</td>\n",
       "      <td>115.721</td>\n",
       "      <td>34.225</td>\n",
       "      <td>24.126</td>\n",
       "      <td>274.148</td>\n",
       "      <td>45.815</td>\n",
       "      <td>3.054</td>\n",
       "      <td>91.628</td>\n",
       "      <td>...</td>\n",
       "      <td>42.759</td>\n",
       "      <td>-81.432</td>\n",
       "      <td>11.307</td>\n",
       "      <td>-27.366</td>\n",
       "      <td>-1.250639</td>\n",
       "      <td>0.040408</td>\n",
       "      <td>-1.085167</td>\n",
       "      <td>0.306294</td>\n",
       "      <td>0.041408</td>\n",
       "      <td>846.9825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ddate security_code       時価総額         売上      営業利益       純利益        総資産  \\\n",
       "0   2000           AAL     0.0000  14824.000  2368.000  1957.000  30616.000   \n",
       "1   2000           ABF  3385.8000   4406.000   327.000   138.000   3867.000   \n",
       "2   2000           ACL   121.9050    245.360    13.484     8.232    146.453   \n",
       "3   2000           ADB     0.0000     32.645     2.448     1.466     23.528   \n",
       "4   2000           ADN   846.9825    115.721    34.225    24.126    274.148   \n",
       "\n",
       "   現金･現金同等物      有価証券      流動資産    ...          営業資産      営業負債       有形固定  \\\n",
       "0  1061.000  2344.000  8127.000    ...      4722.000 -4027.000  11819.000   \n",
       "1    65.000  1133.000  2220.000    ...      1022.000  -735.000   1459.000   \n",
       "2     8.461     0.000    86.766    ...        78.305   -54.935      9.342   \n",
       "3     0.412     0.000     6.764    ...         6.352    -5.785     16.087   \n",
       "4    45.815     3.054    91.628    ...        42.759   -81.432     11.307   \n",
       "\n",
       "        使用資産      ROIC        EY     MAGIC     ROIC2       EY2     MKTCAP  \n",
       "0  12514.000  0.189228       inf       inf  0.114236  0.401220     0.0000  \n",
       "1   1746.000  0.187285  0.096580  0.265137  0.111833  0.092430  3385.8000  \n",
       "2     32.712  0.412203  0.110611  0.481594  0.390139  0.092395   121.9050  \n",
       "3     16.654  0.146992       inf       inf  0.185581  0.528041     0.0000  \n",
       "4    -27.366 -1.250639  0.040408 -1.085167  0.306294  0.041408   846.9825  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv with adjusted MKTCAP\n",
    "# ALLDF['時価総額']*(ALLDF['発行済株式数']-ALLDF['自己株式数'])/ALLDF['発行済株式数']\n",
    "raw = pd.read_csv('MKTCAP_LN.csv', encoding = 'cp932').dropna()\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13620, 76)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3987, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any zero or blow zero MKTCAP values\n",
    "raw[raw['MKTCAP'] < 0][['security_code', '時価総額', 'MKTCAP']].head()\n",
    "\n",
    "print (raw.shape)\n",
    "raw[raw['MKTCAP'] == 0][['security_code', '時価総額', 'MKTCAP']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502814, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>security_code</th>\n",
       "      <th>ddate</th>\n",
       "      <th>quarter</th>\n",
       "      <th>title</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7DIG</td>\n",
       "      <td>2001</td>\n",
       "      <td>200101</td>\n",
       "      <td>ANNOUNCEMENT_DT</td>\n",
       "      <td>2.001070e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7DIG</td>\n",
       "      <td>2001</td>\n",
       "      <td>200101</td>\n",
       "      <td>BS_ACCT_NOTE_RCV</td>\n",
       "      <td>6.470000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7DIG</td>\n",
       "      <td>2001</td>\n",
       "      <td>200101</td>\n",
       "      <td>BS_ACCT_PAYABLE</td>\n",
       "      <td>3.200000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7DIG</td>\n",
       "      <td>2001</td>\n",
       "      <td>200101</td>\n",
       "      <td>BS_CASH_NEAR_CASH_ITEM</td>\n",
       "      <td>2.368000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7DIG</td>\n",
       "      <td>2001</td>\n",
       "      <td>200101</td>\n",
       "      <td>BS_CUR_ASSET_REPORT</td>\n",
       "      <td>3.393000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  security_code  ddate  quarter                   title         value\n",
       "0          7DIG   2001   200101         ANNOUNCEMENT_DT  2.001070e+07\n",
       "1          7DIG   2001   200101        BS_ACCT_NOTE_RCV  6.470000e-01\n",
       "2          7DIG   2001   200101         BS_ACCT_PAYABLE  3.200000e-01\n",
       "3          7DIG   2001   200101  BS_CASH_NEAR_CASH_ITEM  2.368000e+00\n",
       "4          7DIG   2001   200101     BS_CUR_ASSET_REPORT  3.393000e+00"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv with unadjusted MKTCAP\n",
    "df = pd.read_csv('sqldataln.csv', encoding = 'cp932')\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# aal = df[df['security_code'] == 'AAL']\n",
    "# aal[aal['title'] == 'HISTORICAL_MARKET_CAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = pd.merge(raw, df, how = 'left', left_on = ['security_code', 'ddate'], right_on = ['security_code', 'ddate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ddate</th>\n",
       "      <th>security_code</th>\n",
       "      <th>時価総額</th>\n",
       "      <th>売上</th>\n",
       "      <th>営業利益</th>\n",
       "      <th>純利益</th>\n",
       "      <th>総資産</th>\n",
       "      <th>現金･現金同等物</th>\n",
       "      <th>有価証券</th>\n",
       "      <th>流動資産</th>\n",
       "      <th>...</th>\n",
       "      <th>使用資産</th>\n",
       "      <th>ROIC</th>\n",
       "      <th>EY</th>\n",
       "      <th>MAGIC</th>\n",
       "      <th>ROIC2</th>\n",
       "      <th>EY2</th>\n",
       "      <th>MKTCAP</th>\n",
       "      <th>quarter</th>\n",
       "      <th>title</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2000</td>\n",
       "      <td>AAL</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14824.000</td>\n",
       "      <td>2368.000</td>\n",
       "      <td>1957.000</td>\n",
       "      <td>30616.000</td>\n",
       "      <td>1061.000</td>\n",
       "      <td>2344.000</td>\n",
       "      <td>8127.000</td>\n",
       "      <td>...</td>\n",
       "      <td>12514.000</td>\n",
       "      <td>0.189228</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.114236</td>\n",
       "      <td>0.401220</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>200001</td>\n",
       "      <td>HISTORICAL_MARKET_CAP</td>\n",
       "      <td>22469.2680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2000</td>\n",
       "      <td>ABF</td>\n",
       "      <td>3385.8000</td>\n",
       "      <td>4406.000</td>\n",
       "      <td>327.000</td>\n",
       "      <td>138.000</td>\n",
       "      <td>3867.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>1133.000</td>\n",
       "      <td>2220.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1746.000</td>\n",
       "      <td>0.187285</td>\n",
       "      <td>0.096580</td>\n",
       "      <td>0.265137</td>\n",
       "      <td>0.111833</td>\n",
       "      <td>0.092430</td>\n",
       "      <td>3385.8000</td>\n",
       "      <td>200001</td>\n",
       "      <td>HISTORICAL_MARKET_CAP</td>\n",
       "      <td>2652.1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACL</td>\n",
       "      <td>121.9050</td>\n",
       "      <td>245.360</td>\n",
       "      <td>13.484</td>\n",
       "      <td>8.232</td>\n",
       "      <td>146.453</td>\n",
       "      <td>8.461</td>\n",
       "      <td>0.000</td>\n",
       "      <td>86.766</td>\n",
       "      <td>...</td>\n",
       "      <td>32.712</td>\n",
       "      <td>0.412203</td>\n",
       "      <td>0.110611</td>\n",
       "      <td>0.481594</td>\n",
       "      <td>0.390139</td>\n",
       "      <td>0.092395</td>\n",
       "      <td>121.9050</td>\n",
       "      <td>200001</td>\n",
       "      <td>HISTORICAL_MARKET_CAP</td>\n",
       "      <td>116.6681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2000</td>\n",
       "      <td>ADB</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32.645</td>\n",
       "      <td>2.448</td>\n",
       "      <td>1.466</td>\n",
       "      <td>23.528</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.764</td>\n",
       "      <td>...</td>\n",
       "      <td>16.654</td>\n",
       "      <td>0.146992</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.185581</td>\n",
       "      <td>0.528041</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>200001</td>\n",
       "      <td>HISTORICAL_MARKET_CAP</td>\n",
       "      <td>20.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2000</td>\n",
       "      <td>ADN</td>\n",
       "      <td>846.9825</td>\n",
       "      <td>115.721</td>\n",
       "      <td>34.225</td>\n",
       "      <td>24.126</td>\n",
       "      <td>274.148</td>\n",
       "      <td>45.815</td>\n",
       "      <td>3.054</td>\n",
       "      <td>91.628</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.366</td>\n",
       "      <td>-1.250639</td>\n",
       "      <td>0.040408</td>\n",
       "      <td>-1.085167</td>\n",
       "      <td>0.306294</td>\n",
       "      <td>0.041408</td>\n",
       "      <td>846.9825</td>\n",
       "      <td>200001</td>\n",
       "      <td>HISTORICAL_MARKET_CAP</td>\n",
       "      <td>884.2819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ddate security_code       時価総額         売上      営業利益       純利益        総資産  \\\n",
       "21    2000           AAL     0.0000  14824.000  2368.000  1957.000  30616.000   \n",
       "51    2000           ABF  3385.8000   4406.000   327.000   138.000   3867.000   \n",
       "80    2000           ACL   121.9050    245.360    13.484     8.232    146.453   \n",
       "109   2000           ADB     0.0000     32.645     2.448     1.466     23.528   \n",
       "138   2000           ADN   846.9825    115.721    34.225    24.126    274.148   \n",
       "\n",
       "     現金･現金同等物      有価証券      流動資産     ...           使用資産      ROIC        EY  \\\n",
       "21   1061.000  2344.000  8127.000     ...      12514.000  0.189228       inf   \n",
       "51     65.000  1133.000  2220.000     ...       1746.000  0.187285  0.096580   \n",
       "80      8.461     0.000    86.766     ...         32.712  0.412203  0.110611   \n",
       "109     0.412     0.000     6.764     ...         16.654  0.146992       inf   \n",
       "138    45.815     3.054    91.628     ...        -27.366 -1.250639  0.040408   \n",
       "\n",
       "        MAGIC     ROIC2       EY2     MKTCAP  quarter                  title  \\\n",
       "21        inf  0.114236  0.401220     0.0000   200001  HISTORICAL_MARKET_CAP   \n",
       "51   0.265137  0.111833  0.092430  3385.8000   200001  HISTORICAL_MARKET_CAP   \n",
       "80   0.481594  0.390139  0.092395   121.9050   200001  HISTORICAL_MARKET_CAP   \n",
       "109       inf  0.185581  0.528041     0.0000   200001  HISTORICAL_MARKET_CAP   \n",
       "138 -1.085167  0.306294  0.041408   846.9825   200001  HISTORICAL_MARKET_CAP   \n",
       "\n",
       "          value  \n",
       "21   22469.2680  \n",
       "51    2652.1079  \n",
       "80     116.6681  \n",
       "109     20.2960  \n",
       "138    884.2819  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unadjust = new[new['title'] == 'HISTORICAL_MARKET_CAP'].dropna()\n",
    "unadjust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13620, 76)\n",
      "(13236, 79)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>security_code</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [security_code, value]\n",
       "Index: []"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any zero or below zero MKTCAP vlaue \n",
    "mktcap_value = unadjust[unadjust['title'] == 'HISTORICAL_MARKET_CAP'][['security_code', 'value']]\n",
    "mktcap_value[mktcap_value['value'] == 0]\n",
    "print(raw.shape)\n",
    "print (unadjust.shape)\n",
    "mktcap_value[mktcap_value['value'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collist = unadjust.columns.tolist()\n",
    "raw2 = unadjust.drop(collist[-9: -1], axis = 1)\n",
    "\n",
    "# x = data.iloc[:, :-1]\n",
    "# y = data['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = []\n",
    "# for i in range(len(raw['security_code'])):\n",
    "#     if np.unique(raw['security_code'])[i] != np.unique(unadjust['security_code'])[i]:\n",
    "#         print (i)\n",
    "#         l.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13236, 71)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>security_code</th>\n",
       "      <th>時価総額</th>\n",
       "      <th>売上</th>\n",
       "      <th>営業利益</th>\n",
       "      <th>純利益</th>\n",
       "      <th>総資産</th>\n",
       "      <th>現金･現金同等物</th>\n",
       "      <th>有価証券</th>\n",
       "      <th>流動資産</th>\n",
       "      <th>総長期投資</th>\n",
       "      <th>...</th>\n",
       "      <th>販管費</th>\n",
       "      <th>売上総利益率</th>\n",
       "      <th>営業利益率</th>\n",
       "      <th>株主還元</th>\n",
       "      <th>純現金資産</th>\n",
       "      <th>営業資産</th>\n",
       "      <th>営業負債</th>\n",
       "      <th>有形固定</th>\n",
       "      <th>使用資産</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>...</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>...</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>...</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>...</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>...</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>...</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>...</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>...</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>...</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>...</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>...</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>...</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>...</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>...</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       security_code  時価総額    売上  営業利益   純利益   総資産  現金･現金同等物  有価証券  流動資産  \\\n",
       "ddate                                                                      \n",
       "2000             439   439   439   439   439   439       439   439   439   \n",
       "2001             467   467   467   467   467   467       467   467   467   \n",
       "2002             484   484   484   484   484   484       484   484   484   \n",
       "2003             486   486   486   486   486   486       486   486   486   \n",
       "2004             540   540   540   540   540   540       540   540   540   \n",
       "2005             620   620   620   620   620   620       620   620   620   \n",
       "2006             714   714   714   714   714   714       714   714   714   \n",
       "2007             778   778   778   778   778   778       778   778   778   \n",
       "2008             826   826   826   826   826   826       826   826   826   \n",
       "2009             834   834   834   834   834   834       834   834   834   \n",
       "2010             865   865   865   865   865   865       865   865   865   \n",
       "2011             888   888   888   888   888   888       888   888   888   \n",
       "2012             901   901   901   901   901   901       901   901   901   \n",
       "2013             921   921   921   921   921   921       921   921   921   \n",
       "2014            1004  1004  1004  1004  1004  1004      1004  1004  1004   \n",
       "2015            1080  1080  1080  1080  1080  1080      1080  1080  1080   \n",
       "2016            1146  1146  1146  1146  1146  1146      1146  1146  1146   \n",
       "2017             243   243   243   243   243   243       243   243   243   \n",
       "\n",
       "       総長期投資  ...     販管費  売上総利益率  営業利益率  株主還元  純現金資産  営業資産  営業負債  有形固定  使用資産  \\\n",
       "ddate         ...                                                               \n",
       "2000     439  ...     439     439    439   439    439   439   439   439   439   \n",
       "2001     467  ...     467     467    467   467    467   467   467   467   467   \n",
       "2002     484  ...     484     484    484   484    484   484   484   484   484   \n",
       "2003     486  ...     486     486    486   486    486   486   486   486   486   \n",
       "2004     540  ...     540     540    540   540    540   540   540   540   540   \n",
       "2005     620  ...     620     620    620   620    620   620   620   620   620   \n",
       "2006     714  ...     714     714    714   714    714   714   714   714   714   \n",
       "2007     778  ...     778     778    778   778    778   778   778   778   778   \n",
       "2008     826  ...     826     826    826   826    826   826   826   826   826   \n",
       "2009     834  ...     834     834    834   834    834   834   834   834   834   \n",
       "2010     865  ...     865     865    865   865    865   865   865   865   865   \n",
       "2011     888  ...     888     888    888   888    888   888   888   888   888   \n",
       "2012     901  ...     901     901    901   901    901   901   901   901   901   \n",
       "2013     921  ...     921     921    921   921    921   921   921   921   921   \n",
       "2014    1004  ...    1004    1004   1004  1004   1004  1004  1004  1004  1004   \n",
       "2015    1080  ...    1080    1080   1080  1080   1080  1080  1080  1080  1080   \n",
       "2016    1146  ...    1146    1146   1146  1146   1146  1146  1146  1146  1146   \n",
       "2017     243  ...     243     243    243   243    243   243   243   243   243   \n",
       "\n",
       "       value  \n",
       "ddate         \n",
       "2000     439  \n",
       "2001     467  \n",
       "2002     484  \n",
       "2003     486  \n",
       "2004     540  \n",
       "2005     620  \n",
       "2006     714  \n",
       "2007     778  \n",
       "2008     826  \n",
       "2009     834  \n",
       "2010     865  \n",
       "2011     888  \n",
       "2012     901  \n",
       "2013     921  \n",
       "2014    1004  \n",
       "2015    1080  \n",
       "2016    1146  \n",
       "2017     243  \n",
       "\n",
       "[18 rows x 70 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw2.groupby('ddate').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1060, 62)\n"
     ]
    }
   ],
   "source": [
    "# remove all zero columns. i.e. keep columns that have all zero values \n",
    "data = raw2.loc[:, (raw2 != 0).any(axis = 0)]\n",
    "\n",
    "# only keep the companeis that exist in both 2014 and 2015\n",
    "x_2015= data[data['ddate'] == 2015].drop('value', axis = 1)\n",
    "y_2016 = data[data['ddate'] == 2016][['security_code','value']]\n",
    "\n",
    "data2 = pd.merge(x_2015, y_2016, how = 'inner', on = ['security_code'])\n",
    "print (data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAJMCAYAAACRnCB2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xedd9ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10, 10))\n",
    "\n",
    "num = len(data2['security_code'])\n",
    "x_plot = np.arange(num)\n",
    "y_plot = data2['value']\n",
    "my_ticks = list(data2['security_code'].values)\n",
    "\n",
    "plt.xticks(x_plot, my_ticks)\n",
    "plt.scatter(x_plot, y_plot)\n",
    "\n",
    "plt.ylabel('MKTCAP')\n",
    "plt.xlabel('company tickers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1060.000000\n",
       "mean       3314.049922\n",
       "std       22818.849173\n",
       "min           0.038700\n",
       "25%          19.131375\n",
       "50%         107.687400\n",
       "75%         740.914625\n",
       "max      539463.030000\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ddate</th>\n",
       "      <th>security_code</th>\n",
       "      <th>時価総額</th>\n",
       "      <th>売上</th>\n",
       "      <th>営業利益</th>\n",
       "      <th>純利益</th>\n",
       "      <th>総資産</th>\n",
       "      <th>現金･現金同等物</th>\n",
       "      <th>有価証券</th>\n",
       "      <th>流動資産</th>\n",
       "      <th>...</th>\n",
       "      <th>販管費</th>\n",
       "      <th>売上総利益率</th>\n",
       "      <th>営業利益率</th>\n",
       "      <th>株主還元</th>\n",
       "      <th>純現金資産</th>\n",
       "      <th>営業資産</th>\n",
       "      <th>営業負債</th>\n",
       "      <th>有形固定</th>\n",
       "      <th>使用資産</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>7DIG</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.365</td>\n",
       "      <td>1.742</td>\n",
       "      <td>-7.913</td>\n",
       "      <td>7.339</td>\n",
       "      <td>1.656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.220</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.315</td>\n",
       "      <td>0.680849</td>\n",
       "      <td>0.168066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.656</td>\n",
       "      <td>4.564</td>\n",
       "      <td>-3.974</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.293</td>\n",
       "      <td>7.3014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>462.100</td>\n",
       "      <td>40.800</td>\n",
       "      <td>29.500</td>\n",
       "      <td>386.300</td>\n",
       "      <td>178.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.200</td>\n",
       "      <td>...</td>\n",
       "      <td>40.800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.000</td>\n",
       "      <td>35.600</td>\n",
       "      <td>-222.400</td>\n",
       "      <td>11.200</td>\n",
       "      <td>-175.600</td>\n",
       "      <td>960.6034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>AA/</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>984.000</td>\n",
       "      <td>325.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>1958.000</td>\n",
       "      <td>302.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-313.000</td>\n",
       "      <td>0.648374</td>\n",
       "      <td>0.330285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2940.000</td>\n",
       "      <td>193.000</td>\n",
       "      <td>-471.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>-178.000</td>\n",
       "      <td>1790.4874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>AAL</td>\n",
       "      <td>5131.8597</td>\n",
       "      <td>20455.000</td>\n",
       "      <td>-4261.000</td>\n",
       "      <td>-5624.000</td>\n",
       "      <td>52013.000</td>\n",
       "      <td>6895.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13797.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3237.000</td>\n",
       "      <td>-0.050061</td>\n",
       "      <td>-0.208311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10226.000</td>\n",
       "      <td>6902.000</td>\n",
       "      <td>-4207.000</td>\n",
       "      <td>29621.000</td>\n",
       "      <td>32316.000</td>\n",
       "      <td>18308.3621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>AAZ</td>\n",
       "      <td>12.1111</td>\n",
       "      <td>78.057</td>\n",
       "      <td>-2.940</td>\n",
       "      <td>-7.381</td>\n",
       "      <td>172.041</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.577</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.763</td>\n",
       "      <td>0.036166</td>\n",
       "      <td>-0.037665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49.047</td>\n",
       "      <td>42.328</td>\n",
       "      <td>-20.112</td>\n",
       "      <td>112.288</td>\n",
       "      <td>134.504</td>\n",
       "      <td>33.3792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ddate security_code       時価総額         売上      営業利益       純利益        総資産  \\\n",
       "0   2015          7DIG     0.0000     10.365     1.742    -7.913      7.339   \n",
       "1   2015           888     0.0000    462.100    40.800    29.500    386.300   \n",
       "2   2015           AA/     0.0000    984.000   325.000    69.000   1958.000   \n",
       "3   2015           AAL  5131.8597  20455.000 -4261.000 -5624.000  52013.000   \n",
       "4   2015           AAZ    12.1111     78.057    -2.940    -7.381    172.041   \n",
       "\n",
       "   現金･現金同等物  有価証券       流動資産     ...           販管費    売上総利益率     営業利益率  株主還元  \\\n",
       "0     1.656   0.0      6.220     ...        -5.315  0.680849  0.168066   0.0   \n",
       "1   178.600   0.0    214.200     ...        40.800  0.000000  0.088293   0.0   \n",
       "2   302.000   0.0    495.000     ...      -313.000  0.648374  0.330285   0.0   \n",
       "3  6895.000   0.0  13797.000     ...     -3237.000 -0.050061 -0.208311   0.0   \n",
       "4     0.249   0.0     42.577     ...        -5.763  0.036166 -0.037665   0.0   \n",
       "\n",
       "       純現金資産      営業資産      営業負債       有形固定       使用資産       value  \n",
       "0      1.656     4.564    -3.974      0.703      1.293      7.3014  \n",
       "1    181.000    35.600  -222.400     11.200   -175.600    960.6034  \n",
       "2  -2940.000   193.000  -471.000    100.000   -178.000   1790.4874  \n",
       "3 -10226.000  6902.000 -4207.000  29621.000  32316.000  18308.3621  \n",
       "4    -49.047    42.328   -20.112    112.288    134.504     33.3792  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ddate</th>\n",
       "      <th>security_code</th>\n",
       "      <th>時価総額</th>\n",
       "      <th>売上</th>\n",
       "      <th>営業利益</th>\n",
       "      <th>純利益</th>\n",
       "      <th>総資産</th>\n",
       "      <th>現金･現金同等物</th>\n",
       "      <th>有価証券</th>\n",
       "      <th>流動資産</th>\n",
       "      <th>...</th>\n",
       "      <th>販管費</th>\n",
       "      <th>売上総利益率</th>\n",
       "      <th>営業利益率</th>\n",
       "      <th>株主還元</th>\n",
       "      <th>純現金資産</th>\n",
       "      <th>営業資産</th>\n",
       "      <th>営業負債</th>\n",
       "      <th>有形固定</th>\n",
       "      <th>使用資産</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2015</td>\n",
       "      <td>FIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>808818.0</td>\n",
       "      <td>37281.0</td>\n",
       "      <td>14174.0</td>\n",
       "      <td>402115.0</td>\n",
       "      <td>8958.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108705.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-161109.0</td>\n",
       "      <td>0.245284</td>\n",
       "      <td>0.046093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-130429.0</td>\n",
       "      <td>99747.0</td>\n",
       "      <td>-148210.0</td>\n",
       "      <td>189000.0</td>\n",
       "      <td>140537.0</td>\n",
       "      <td>539463.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ddate security_code  時価総額        売上     営業利益      純利益       総資産  \\\n",
       "346   2015          FIVE   0.0  808818.0  37281.0  14174.0  402115.0   \n",
       "\n",
       "     現金･現金同等物  有価証券      流動資産    ...           販管費    売上総利益率     営業利益率  株主還元  \\\n",
       "346    8958.0   0.0  108705.0    ...     -161109.0  0.245284  0.046093   0.0   \n",
       "\n",
       "        純現金資産     営業資産      営業負債      有形固定      使用資産      value  \n",
       "346 -130429.0  99747.0 -148210.0  189000.0  140537.0  539463.03  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[data2['value'] == np.max(data2['value'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['売上', '営業利益', '純利益', '総資産', '現金･現金同等物', '有価証券', '流動資産', '総長期投資',\n",
       "       '有形固定資産', '短期借入金', '長期借入金', '流動負債', '無形資産', '未払税金', '短期繰延税金資産', '長期貸付金',\n",
       "       '従業員数', '自己株式の取得', '売上総利益', '土地2', '売掛金', '棚卸', '買掛金', 'のれん･営業権',\n",
       "       '貸倒引当金', '剰余金', '資本金', '売上原価', '負債合計', '自己資本', '未払費用', '長期繰延税金負債',\n",
       "       '長期借入金(当期返済分)', '少数持分', '自己株金額', '人件費', '税引前利益', '非流動資産合計', '自己株式数',\n",
       "       '発行済株式数', '流動資産その他', '投資資産', '無形資産その他', '投資資産その他', '流動負債その他', '固定負債',\n",
       "       '固定負債その他', '自己資本その他', '株主資本', '販管費', '売上総利益率', '営業利益率', '株主還元', '純現金資産',\n",
       "       '営業資産', '営業負債', '有形固定', '使用資産'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data2.iloc[:, 3: 61].columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13620, 76)\n",
      "(13236, 79)\n",
      "(13236, 71)\n"
     ]
    }
   ],
   "source": [
    "print(raw.shape)\n",
    "print (unadjust.shape)\n",
    "print (raw2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-ef1881ebd9d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;34m\"Features selected from Boston using SelectFromModel with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \"threshold %0.3f.\" % sfm.threshold)\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mfeature1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_transform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mfeature2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_transform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_transform' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFXCAYAAABpzN2sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAhoAAAsR0AAAWIiABgDAQgQ0AAAW+n83ZyMJ1nOs8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe294b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = data1.iloc[:, 3: 61], data1.iloc[:, 61]\n",
    "\n",
    "# We use the base estimator LassoCV since the L1 norm promotes sparsity of features.\n",
    "clf = LassoCV()\n",
    "\n",
    "# Set a minimum threshold of 0.25\n",
    "sfm = SelectFromModel(clf, threshold =  25)\n",
    "sfm.fit(X, y)\n",
    "n_features = sfm.transform(X).shape[1]\n",
    "\n",
    "# Reset the threshold till the number of features equals two.\n",
    "# Note that the attribute can be set directly instead of repeatedly\n",
    "# fitting the metatransformer.\n",
    "while n_features > 2:\n",
    "    sfm.threshold += 10\n",
    "    X_transform = sfm.transform(X)\n",
    "    n_features = X_transform.shape[1]\n",
    "\n",
    "# Plot the selected two features from X.\n",
    "plt.title(\n",
    "    \"Features selected from Boston using SelectFromModel with \"\n",
    "    \"threshold %0.3f.\" % sfm.threshold)\n",
    "feature1 = X_transform[:, 0]\n",
    "feature2 = X_transform[:, 1]\n",
    "plt.plot(feature1, feature2, 'r.')\n",
    "plt.xlabel(\"Feature number 1\")\n",
    "plt.ylabel(\"Feature number 2\")\n",
    "plt.ylim([np.min(feature2), np.max(feature2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data2.replace([float('-inf'), float('inf')], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1060, 62)\n",
      "(1059, 62)\n"
     ]
    }
   ],
   "source": [
    "print (data2.shape)\n",
    "print (data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# check for difference between the rows from two dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(raw.shape[0]):\n",
    "    raw.iloc[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['売上', '営業利益', '純利益', '総資産', '現金･現金同等物', '有価証券', '流動資産', '総長期投資',\n",
       "       '有形固定資産', '短期借入金', '長期借入金', '流動負債', '無形資産', '未払税金', '短期繰延税金資産', '長期貸付金',\n",
       "       '従業員数', '自己株式の取得', '売上総利益', '土地2', '売掛金', '棚卸', '買掛金', 'のれん･営業権',\n",
       "       '貸倒引当金', '剰余金', '資本金', '売上原価', '負債合計', '自己資本', '未払費用', '長期繰延税金負債',\n",
       "       '長期借入金(当期返済分)', '少数持分', '自己株金額', '人件費', '税引前利益', '非流動資産合計', '自己株式数',\n",
       "       '発行済株式数', '流動資産その他', '投資資産', '無形資産その他', '投資資産その他', '流動負債その他', '固定負債',\n",
       "       '固定負債その他', '自己資本その他', '株主資本', '販管費', '売上総利益率', '営業利益率', '株主還元', '純現金資産',\n",
       "       '営業資産', '営業負債', '有形固定', '使用資産'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test =  train_test_split(data1[features], data1['value'], test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha = 0.1)\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68776951864976343"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "selected = features[reg.coef_ > 0.01]\n",
    "\n",
    "print (len(selected))\n",
    "print (len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "from sklearn.metrics import make_scorer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "475130435.03126669"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing error estimation of the LASSO just fitted before for feature selection \n",
    "\n",
    "kf = 10\n",
    "\n",
    "MSE = make_scorer(mean_squared_error)\n",
    "np.mean(cross_val_score(reg, data1[features], data1['value'], cv = kf, scoring = MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=5.188e+00, previous alpha=3.351e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=1.523e+01, previous alpha=2.732e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.122e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 7.671e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 54 iterations, alpha=8.804e-01, previous alpha=8.544e-01, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=6.950e+00, previous alpha=7.087e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=2.447e+01, previous alpha=1.915e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=8.067e+01, previous alpha=1.804e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.626e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=3.835e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=3.731e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 6.829e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=3.146e-01, previous alpha=3.037e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=2.049e+02, previous alpha=2.864e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 97 iterations, alpha=1.201e+02, previous alpha=5.926e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=5.648e+01, previous alpha=1.082e-04, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoLarsCV\n",
    "\n",
    "model = LassoLarsCV(cv = 10, precompute=False).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62605608141036884"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['営業利益', '長期借入金', '無形資産', '売掛金', '棚卸', 'のれん･営業権', '剰余金', '長期繰延税金負債',\n",
       "       '税引前利益', '非流動資産合計', '流動負債その他'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[model.coef_ > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "tuned = features[model.coef_ > 0.01]\n",
    "\n",
    "print (len(tuned))\n",
    "print (len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAJaCAYAAAARciKuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQvQiSb6EEEIIIXrR/wfwaLhNOKwt1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcb5ecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot mean square error for each fold\n",
    "\n",
    "m_log_alphascv = np.log10(model.cv_alphas_)\n",
    "\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.plot(m_log_alphascv, model.cv_mse_path_, ':')\n",
    "plt.plot(m_log_alphascv, model.cv_mse_path_.mean(axis = -1), 'red', label = 'Average across the folds')\n",
    "plt.axvline(np.log10(model.alpha_), linestyle = '--', color = 'green', label = 'alpha CV')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('log(alpha)')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.title('Mean squared error on each fold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnkAAAJaCAYAAABTMVE5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAxV/22ov0TVkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe942c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot coefficient progression\n",
    "\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "m_log_alphas = np.log10(model.alphas_)\n",
    "ax = plt.gca()\n",
    "plt.plot(m_log_alphas, model.coef_path_.T)\n",
    "plt.axvline(np.log10(model.alpha_), linestyle = '--', color = 'green', label = 'alpha CV')\n",
    "plt.ylabel('Regression Coefficients')\n",
    "plt.legend()\n",
    "plt.xlabel('log(alpha)')\n",
    "plt.title('Regression Coefficients Progression for Lasso Paths')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV on tuned LASSO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=8.692e+01, previous alpha=1.787e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=2.632e-01, previous alpha=2.055e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=7.196e+00, previous alpha=1.224e-04, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=4.051e+01, previous alpha=1.382e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=9.636e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.593e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.591e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 3.799e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.568e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.536e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.399e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.611e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.579e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.322e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.544e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 88 iterations, alpha=8.050e+01, previous alpha=2.260e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 81 iterations, alpha=2.823e+01, previous alpha=3.630e-04, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=3.865e-01, previous alpha=3.856e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=8.877e+01, previous alpha=1.246e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=3.850e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=2.713e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=2.712e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=1.668e-01, previous alpha=1.662e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=2.157e+02, previous alpha=4.227e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=1.501e+02, previous alpha=3.190e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.239e+02, previous alpha=5.585e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=6.414e+01, previous alpha=4.723e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=1.589e+02, previous alpha=1.452e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.183e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.144e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.134e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.322e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.108e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.322e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.508e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 6.322e-08\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.501e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.616e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=5.083e-01, previous alpha=4.568e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=6.348e+00, previous alpha=3.035e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=6.771e+01, previous alpha=5.734e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=4.852e+01, previous alpha=7.499e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.696e+02, previous alpha=3.536e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=2.557e+01, previous alpha=3.031e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=3.659e+01, previous alpha=1.887e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=2.072e+02, previous alpha=2.792e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=7.269e+01, previous alpha=4.582e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=2.354e+02, previous alpha=7.616e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.582e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.358e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.261e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.050e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=9.701e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 48 iterations, alpha=9.878e-01, previous alpha=7.162e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=2.527e+01, previous alpha=2.581e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=1.536e+02, previous alpha=1.768e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=1.294e+02, previous alpha=7.983e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.945e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.053e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.478e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 5.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.461e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 5.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.119e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 5.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.003e+00, previous alpha=9.968e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=3.023e+01, previous alpha=1.110e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=7.550e+01, previous alpha=1.835e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=1.447e+00, previous alpha=9.152e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=3.716e+01, previous alpha=1.892e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 85 iterations, alpha=5.117e-02, previous alpha=2.777e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=2.651e+01, previous alpha=7.655e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 98 iterations, alpha=4.047e+01, previous alpha=5.428e-05, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 50 iterations, alpha=1.114e+00, previous alpha=1.101e+00, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.518e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 8.560e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=4.194e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.560e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.928e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.996e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.838e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 49 iterations, alpha=4.053e-01, previous alpha=2.026e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=3.443e+01, previous alpha=6.233e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=3.029e+02, previous alpha=5.620e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.516e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.423e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.203e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.057e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.986e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=1.644e+02, previous alpha=4.795e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.398e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.885e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=6.989e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.025e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=5.974e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 7.146e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=5.986e-01, previous alpha=5.794e-01, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 95 iterations, alpha=6.452e-03, previous alpha=5.109e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=1.320e+02, previous alpha=2.196e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=1.341e+02, previous alpha=4.814e-01, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=6.317e+00, previous alpha=1.294e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=5.039e+00, previous alpha=2.347e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=1.089e+02, previous alpha=5.436e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=3.428e+00, previous alpha=4.353e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 82 iterations, alpha=4.512e-01, previous alpha=1.326e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=3.399e-01, previous alpha=3.191e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.111e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 5.960e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=8.165e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=6.783e-01, previous alpha=6.446e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 54 iterations, alpha=7.392e-01, previous alpha=7.033e-01, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=4.789e+01, previous alpha=7.632e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.389e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.212e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.203e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=1.212e-04, previous alpha=1.186e-04, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=1.382e+00, previous alpha=2.492e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.637e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.132e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=5.036e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=4.999e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.161e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=4.953e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 61 iterations, alpha=5.018e-01, previous alpha=4.517e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=2.619e+01, previous alpha=1.428e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=2.008e+01, previous alpha=4.679e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 81 iterations, alpha=4.324e+01, previous alpha=1.695e-06, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=4.698e+01, previous alpha=3.351e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=3.122e+01, previous alpha=3.890e-02, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 80 iterations, alpha=1.653e-01, previous alpha=1.257e-01, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=4.070e+01, previous alpha=9.537e-04, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.262e+02, previous alpha=1.591e-01, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.635e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=8.258e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 4.344e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=6.922e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 4.344e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.945e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.856e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=2.480e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.258e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.155e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=5.073e+01, previous alpha=2.127e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=3.744e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 5.268e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=1.741e+02, previous alpha=3.744e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 81 iterations, alpha=1.744e+01, previous alpha=9.304e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=4.901e+01, previous alpha=1.949e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=4.199e+01, previous alpha=4.434e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=2.021e+00, previous alpha=1.919e+00, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.448e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=3.349e+01, previous alpha=2.390e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=2.681e+00, previous alpha=1.422e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=8.046e-02, previous alpha=4.625e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.989e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=6.395e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.820e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=5.613e-01, previous alpha=4.520e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=1.207e+02, previous alpha=9.870e-01, with an active set of 26 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.752e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.584e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.201e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.090e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.068e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=7.223e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.826e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.529e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.424e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=5.120e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=5.081e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=4.653e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=4.187e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.593e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 58 iterations, alpha=8.835e-01, previous alpha=3.829e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=2.185e+02, previous alpha=4.111e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.042e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.034e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.033e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.019e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.593e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.899e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.093e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.714e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.694e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.788e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.034e-01, previous alpha=6.544e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.660e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=1.427e+02, previous alpha=7.641e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.626e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.989e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.585e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.989e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.568e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=2.631e+00, previous alpha=1.009e+00, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=4.385e+01, previous alpha=3.021e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=7.121e+00, previous alpha=9.717e-02, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.673e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.989e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.924e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.829e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.907e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.788e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.841e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.788e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.638e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=2.331e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 6.664e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=2.301e-01, previous alpha=2.224e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=2.988e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.064e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=1.213e+01, previous alpha=2.469e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=5.295e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.941e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=4.154e+01, previous alpha=4.879e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.836e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 4.081e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.037e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.030e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.543e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.484e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.121e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=1.117e+02, previous alpha=4.024e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=9.280e+01, previous alpha=3.532e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 90 iterations, alpha=2.522e+01, previous alpha=6.799e-06, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=1.654e+02, previous alpha=6.279e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=1.627e+01, previous alpha=1.608e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=1.092e+02, previous alpha=2.789e-05, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=8.461e+00, previous alpha=1.500e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.808e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.025e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.099e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 8.025e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.016e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 51 iterations, alpha=8.268e-01, previous alpha=7.353e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.683e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.215e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.534e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.464e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.337e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 51 iterations, alpha=1.298e+00, previous alpha=1.181e+00, with an active set of 24 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=5.684e-01, previous alpha=2.567e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.333e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.028e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=7.522e+01, previous alpha=4.388e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=5.749e+01, previous alpha=2.912e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 10, MSE_tuned : 75262252.11746648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 101 iterations, alpha=3.851e-05, previous alpha=3.851e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=9.786e+01, previous alpha=1.730e-03, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=9.152e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.543e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 7.376e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 61 iterations, alpha=6.578e-01, previous alpha=6.353e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.547e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.170e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 9.599e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.878e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 4.344e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 61 iterations, alpha=3.814e+01, previous alpha=2.798e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.560e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.689e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.560e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.550e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=1.560e-02, previous alpha=1.490e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 103 iterations, alpha=3.346e+01, previous alpha=3.385e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=5.302e+01, previous alpha=1.454e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.981e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.828e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.332e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.940e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.062e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=4.270e-01, previous alpha=3.991e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.229e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.369e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=1.832e+01, previous alpha=2.839e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=5.749e+01, previous alpha=2.912e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=1.383e+01, previous alpha=5.947e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=3.271e+01, previous alpha=1.464e-01, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=7.465e+01, previous alpha=1.681e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.720e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.424e-08\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.541e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.424e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=8.060e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=8.023e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=7.431e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 42 iterations, alpha=7.814e-01, previous alpha=7.347e-01, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.340e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.483e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.337e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=6.698e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 9.483e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=6.200e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=6.187e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=6.147e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.788e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=5.563e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.816e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=5.276e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=5.140e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=2.694e+01, previous alpha=5.133e-02, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.639e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.996e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.615e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.996e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.082e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 9.940e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.049e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.017e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.031e+00, previous alpha=1.009e+00, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 58 iterations, alpha=8.339e-01, previous alpha=8.339e-01, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=3.139e+01, previous alpha=1.129e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=2.338e+02, previous alpha=4.658e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=1.332e+02, previous alpha=2.921e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=5.024e+01, previous alpha=5.740e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=2.001e+02, previous alpha=2.326e-01, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=3.050e+01, previous alpha=8.125e-02, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.810e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 9.125e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.887e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.714e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.884e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.344e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.784e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.144e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=1.013e+02, previous alpha=1.776e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=7.092e+00, previous alpha=3.743e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=5.170e+01, previous alpha=1.095e-05, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 49 iterations, alpha=8.360e-01, previous alpha=8.197e-01, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 47 iterations, alpha=2.101e+00, previous alpha=2.101e+00, with an active set of 24 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.078e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 9.186e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.074e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 9.186e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.015e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=9.184e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=9.145e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 90 iterations, alpha=1.074e-02, previous alpha=8.908e-03, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.126e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 7.300e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=6.262e+01, previous alpha=5.129e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=5.024e+01, previous alpha=5.740e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 82 iterations, alpha=2.458e-04, previous alpha=2.458e-04, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=1.829e+02, previous alpha=5.170e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=2.150e+02, previous alpha=1.010e-01, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=5.275e+01, previous alpha=3.311e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=1.017e+02, previous alpha=1.274e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 80 iterations, alpha=6.394e+01, previous alpha=9.255e-05, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 41 iterations, alpha=1.282e+00, previous alpha=1.248e+00, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=2.218e+01, previous alpha=9.112e-01, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=5.000e+00, previous alpha=2.440e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=1.427e+02, previous alpha=9.411e-02, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.784e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.541e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=8.389e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.186e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=8.377e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.389e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.065e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 9.714e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.704e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=3.691e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=3.129e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=3.570e-01, previous alpha=3.093e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.376e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.541e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.208e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 55 iterations, alpha=1.046e+00, previous alpha=9.260e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.085e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.018e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=9.648e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=9.645e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=9.067e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.989e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=8.879e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=9.178e-01, previous alpha=8.828e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=4.602e+01, previous alpha=2.230e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=5.427e+01, previous alpha=2.663e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.643e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 9.541e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.639e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.541e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.590e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.888e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.704e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.366e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.309e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.743e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=3.674e-01, previous alpha=2.704e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=5.929e+01, previous alpha=1.687e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=2.331e+01, previous alpha=1.672e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=5.000e+00, previous alpha=2.440e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.506e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.234e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=4.672e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=3.438e-01, previous alpha=3.017e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.762e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.306e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.759e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.744e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.829e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 59 iterations, alpha=2.613e-01, previous alpha=2.591e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=4.453e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.424e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=4.356e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 9.424e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.103e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.599e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.053e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=2.103e-01, previous alpha=1.872e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.208e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 9.996e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.170e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 9.996e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.999e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.799e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.902e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 3.799e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.985e+00, previous alpha=1.865e+00, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=2.277e+01, previous alpha=2.336e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=3.177e+01, previous alpha=4.981e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.289e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 9.306e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.217e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.306e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.397e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.306e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.857e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 9.306e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.845e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 9.306e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.635e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 53 iterations, alpha=7.300e-01, previous alpha=6.624e-01, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 89 iterations, alpha=1.181e+01, previous alpha=8.691e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 80 iterations, alpha=1.430e+00, previous alpha=1.975e-01, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=3.152e+01, previous alpha=8.735e-04, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.684e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 7.671e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=4.555e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 7.743e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=2.657e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=2.383e-01, previous alpha=2.205e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.788e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.541e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.622e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 9.125e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=3.206e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.125e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.987e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 9.125e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.982e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=2.986e-01, previous alpha=2.616e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=1.533e+00, previous alpha=8.433e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=3.327e+01, previous alpha=3.675e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=2.809e+01, previous alpha=9.131e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.578e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.541e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.377e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 9.306e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=1.879e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 9.424e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.443e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.081e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.435e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=3.367e+01, previous alpha=1.317e-01, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.647e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 7.671e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.602e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.308e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.269e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 49 iterations, alpha=5.914e-01, previous alpha=5.834e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=5.718e-02, previous alpha=4.308e-02, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=2.005e+02, previous alpha=5.374e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.684e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 7.671e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=4.555e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 7.743e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=2.657e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=2.383e-01, previous alpha=2.205e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=7.977e+01, previous alpha=2.944e-04, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=6.188e-05, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.909e-08\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.319e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 7.300e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.316e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.203e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 6.234e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.196e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 8.429e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.083e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 85 iterations, alpha=3.319e-05, previous alpha=3.015e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 80 iterations, alpha=2.304e+00, previous alpha=1.369e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=4.800e+01, previous alpha=1.152e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=1.137e+02, previous alpha=2.177e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=1.127e+01, previous alpha=1.952e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=2.777e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=2.776e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=2.611e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.246e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=2.605e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=2.646e-01, previous alpha=2.396e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=4.518e-01, previous alpha=2.177e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=9.220e+01, previous alpha=2.925e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=6.758e+01, previous alpha=2.232e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=3.138e+01, previous alpha=1.022e-01, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=2.502e+01, previous alpha=9.389e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=7.649e+01, previous alpha=4.966e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=1.744e+01, previous alpha=4.551e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=1.108e+01, previous alpha=3.361e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.436e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.424e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.094e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.424e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.012e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 47 iterations, alpha=1.053e+00, previous alpha=9.573e-01, with an active set of 26 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=3.863e+00, previous alpha=8.215e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=2.952e+01, previous alpha=2.042e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.237e+00, previous alpha=3.336e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=3.138e+01, previous alpha=1.022e-01, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=1.167e-01, previous alpha=1.147e-01, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=3.192e-01, previous alpha=2.143e-01, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=1.236e+02, previous alpha=1.185e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=1.561e+02, previous alpha=5.288e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=1.691e+00, previous alpha=4.969e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=1.906e+00, previous alpha=2.984e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=2.566e+02, previous alpha=3.299e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=7.797e-01, previous alpha=2.468e-04, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=5.836e+01, previous alpha=1.498e-01, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 85 iterations, alpha=6.043e-01, previous alpha=1.868e-04, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.456e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.816e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.361e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.816e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.079e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 59 iterations, alpha=7.358e-01, previous alpha=6.261e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=6.029e+00, previous alpha=5.448e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=4.304e+01, previous alpha=1.212e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=2.727e-01, previous alpha=2.186e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=5.442e-01, previous alpha=3.566e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=1.214e+00, previous alpha=1.214e+00, with an active set of 26 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 81 iterations, alpha=5.703e+01, previous alpha=9.988e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=5.590e+01, previous alpha=3.414e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.584e+00, previous alpha=3.884e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.456e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.816e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.361e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.816e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.079e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 59 iterations, alpha=7.358e-01, previous alpha=6.261e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=4.817e+01, previous alpha=1.463e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=4.011e+01, previous alpha=4.932e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.244e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=4.442e+00, previous alpha=2.484e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=4.687e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 9.657e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.507e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 9.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=4.179e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 9.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=3.920e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=1.052e+02, previous alpha=2.771e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.041e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.405e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.401e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=9.414e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.752e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 50 iterations, alpha=9.308e-01, previous alpha=9.304e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=9.823e+01, previous alpha=4.368e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=4.863e+01, previous alpha=2.380e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=1.765e+00, previous alpha=3.495e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=2.226e+01, previous alpha=2.567e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=4.523e-05, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.297e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.230e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 8.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.215e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.194e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 4.593e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.093e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.268e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.066e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.063e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.967e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 8.941e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 97 iterations, alpha=2.701e+01, previous alpha=1.940e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=9.263e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.996e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.950e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.996e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.731e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 5.960e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.669e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=1.580e+02, previous alpha=4.274e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=1.138e+02, previous alpha=1.299e+00, with an active set of 26 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=1.132e+02, previous alpha=2.764e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=3.326e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 89 iterations, alpha=1.047e+02, previous alpha=6.572e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.338e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.843e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 9.714e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.280e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 9.714e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.223e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 9.714e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.016e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.867e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.013e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 4.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 57 iterations, alpha=6.178e-01, previous alpha=5.728e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=1.393e+00, previous alpha=1.316e+00, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 82 iterations, alpha=4.205e+01, previous alpha=6.622e-02, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=4.111e+01, previous alpha=4.981e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.021e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=6.238e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 80 iterations, alpha=9.144e-01, previous alpha=4.065e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.412e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 8.689e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.407e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.081e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=3.296e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.081e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=3.152e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=3.295e-01, previous alpha=2.979e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=9.263e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.996e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.950e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 9.996e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.731e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 5.960e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.669e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=1.580e+02, previous alpha=4.274e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=8.318e+01, previous alpha=1.629e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=1.393e+02, previous alpha=3.897e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=9.702e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 9.657e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=9.688e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=5.947e+01, previous alpha=9.419e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=2.561e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.714e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=2.426e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 6.144e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=2.561e-01, previous alpha=2.145e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=6.958e+01, previous alpha=3.646e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=5.423e+01, previous alpha=2.724e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=7.395e+01, previous alpha=1.019e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=1.756e+02, previous alpha=4.816e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.387e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 8.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.879e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 8.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=2.994e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=2.642e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 9.306e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 49 iterations, alpha=2.863e-01, previous alpha=2.317e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 82 iterations, alpha=5.206e+01, previous alpha=5.682e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=2.824e+00, previous alpha=2.450e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.743e+01, previous alpha=3.546e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=5.139e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 9.996e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.224e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 9.657e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.195e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.079e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.056e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=1.953e-01, previous alpha=1.788e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=1.163e+02, previous alpha=5.377e-01, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=5.564e+01, previous alpha=5.840e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=1.916e+01, previous alpha=1.112e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=5.484e+01, previous alpha=1.885e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 89 iterations, alpha=8.134e-01, previous alpha=1.705e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=4.570e-01, previous alpha=2.171e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=5.796e+01, previous alpha=1.492e+00, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=2.824e+00, previous alpha=2.450e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=9.028e+01, previous alpha=1.292e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 93 iterations, alpha=8.566e+00, previous alpha=9.510e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=1.057e+01, previous alpha=7.937e-01, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=5.599e+01, previous alpha=7.910e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=4.730e+01, previous alpha=1.591e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=9.726e+01, previous alpha=5.565e-01, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=3.354e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.424e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=3.237e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.424e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=3.232e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=3.215e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.161e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=3.000e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=3.237e-01, previous alpha=2.510e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=5.326e+01, previous alpha=5.404e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=8.660e+00, previous alpha=4.396e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=3.054e+01, previous alpha=1.738e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.343e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=4.735e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=4.734e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=4.377e-01, previous alpha=4.116e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=3.846e+01, previous alpha=5.747e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=5.489e+01, previous alpha=2.780e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=7.191e+01, previous alpha=3.169e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.076e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=9.509e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=7.801e-01, previous alpha=7.532e-01, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=3.689e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.560e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.687e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 8.560e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.681e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.662e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.418e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=3.664e-01, previous alpha=3.190e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 49 iterations, alpha=1.539e+00, previous alpha=1.533e+00, with an active set of 26 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=7.361e+01, previous alpha=2.340e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=3.054e+01, previous alpha=1.738e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.735e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.733e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 4.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.684e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 4.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.605e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.583e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.470e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.408e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.674e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.141e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.074e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 9.657e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=8.866e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 6.829e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=7.772e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.745e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=2.922e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.932e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.892e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.746e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=2.413e+01, previous alpha=1.849e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=5.416e+00, previous alpha=2.266e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.112e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.144e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=6.494e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 6.409e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=6.485e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=3.247e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=3.218e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=3.116e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=3.463e+02, previous alpha=2.736e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=4.356e+01, previous alpha=1.844e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=9.520e+01, previous alpha=2.029e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.350e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.186e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=3.024e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=3.019e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=3.003e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=7.595e+01, previous alpha=2.831e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=1.817e+02, previous alpha=5.324e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=4.546e+00, previous alpha=9.370e-02, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=3.701e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=3.687e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=3.682e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=3.412e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.593e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.916e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 6.144e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.900e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.502e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.469e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.384e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.352e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.348e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.346e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.247e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.105e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.044e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.033e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.960e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=5.925e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=5.018e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.344e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=3.233e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.268e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.699e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=3.750e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=3.130e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.344e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.975e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.971e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.955e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.952e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.753e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.593e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.584e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.960e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.437e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.144e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.910e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.868e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.585e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.405e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.190e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.112e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=8.873e-05, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 88 iterations, alpha=3.257e+01, previous alpha=6.178e-05, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=6.388e-01, previous alpha=6.388e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=5.582e-01, previous alpha=3.571e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-9b680e4a5739>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mMSE_tuned\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1119\u001b[0m                 \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m                 max_iter=self.max_iter, eps=self.eps, positive=self.positive)\n\u001b[1;32m-> 1121\u001b[1;33m             for train, test in cv.split(X, y))\n\u001b[0m\u001b[0;32m   1122\u001b[0m         \u001b[0mall_alphas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcv_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[1;31m# Unique also sorts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py\u001b[0m in \u001b[0;36m_lars_path_residues\u001b[1;34m(X_train, y_train, X_test, y_test, Gram, copy, method, verbose, fit_intercept, normalize, max_iter, eps, positive)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_Gram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m         positive=positive)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0mcoefs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnonzeros\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnonzeros\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py\u001b[0m in \u001b[0;36mlars_path\u001b[1;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;31m# correlation between each unactive variables and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m             \u001b[1;31m# eqiangular vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m             \u001b[0mcorr_eq_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_active\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meq_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;31m# if huge number of features, this takes 50% of time, I\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model\n",
    "folds      = [10, 20, 50, 100, 150, 200, 250]\n",
    "n_folds    = len(folds)\n",
    "MSE_tuned  = []\n",
    "n = data1[features].shape[0]\n",
    "\n",
    "MSE = make_scorer(mean_squared_error)\n",
    "\n",
    "# Run K-folds\n",
    "for k in folds:\n",
    "\n",
    "    scores = cross_val_score(model, data1[features], data1['value'], cv = k, scoring = MSE)\n",
    "    MSE_tuned .append(scores.mean())\n",
    "\n",
    "    print(\"K = {}, MSE_tuned : {}\".format (k, MSE_tuned[-1]))\n",
    "    \n",
    "    \n",
    "# Print chart\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "plt.errorbar(range(1, n_folds + 1), MSE_tuned , yerr=[5] * n_folds)  # Use 5% for the error bars\n",
    "ax = plt.gca()\n",
    "plt.xticks(range(0, n_folds + 2), [''] + [str(k) for k in folds] + [''])\n",
    "# plt.yticks(range(30, 110, 10))\n",
    "\n",
    "plt.title(\"K-fold Cross-validation testing error estimation\")\n",
    "plt.xlabel(\"number of folds\")\n",
    "plt.ylabel(\"MSE_tuned \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=8.692e+01, previous alpha=1.787e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=2.632e-01, previous alpha=2.055e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=7.196e+00, previous alpha=1.224e-04, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=4.051e+01, previous alpha=1.382e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=9.636e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.593e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.591e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 3.799e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.568e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.536e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=3.399e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.611e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.579e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.322e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.544e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 88 iterations, alpha=8.050e+01, previous alpha=2.260e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 81 iterations, alpha=2.823e+01, previous alpha=3.630e-04, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=3.865e-01, previous alpha=3.856e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=8.877e+01, previous alpha=1.246e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=3.850e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=2.713e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=2.712e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=1.668e-01, previous alpha=1.662e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=2.157e+02, previous alpha=4.227e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=1.501e+02, previous alpha=3.190e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.239e+02, previous alpha=5.585e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=6.414e+01, previous alpha=4.723e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=1.589e+02, previous alpha=1.452e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.183e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.144e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.134e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.322e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.108e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.322e-08\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.508e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 6.322e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.501e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.616e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=5.083e-01, previous alpha=4.568e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=6.348e+00, previous alpha=3.035e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=6.771e+01, previous alpha=5.734e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=4.852e+01, previous alpha=7.499e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.696e+02, previous alpha=3.536e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=2.557e+01, previous alpha=3.031e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=3.659e+01, previous alpha=1.887e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=2.072e+02, previous alpha=2.792e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=7.269e+01, previous alpha=4.582e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=2.354e+02, previous alpha=7.616e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.582e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.358e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.261e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.050e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=9.701e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 48 iterations, alpha=9.878e-01, previous alpha=7.162e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=2.527e+01, previous alpha=2.581e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=1.536e+02, previous alpha=1.768e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=1.294e+02, previous alpha=7.983e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.945e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.053e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.478e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 5.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.461e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 5.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.119e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 5.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.003e+00, previous alpha=9.968e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=3.023e+01, previous alpha=1.110e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=7.550e+01, previous alpha=1.835e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=1.447e+00, previous alpha=9.152e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=3.716e+01, previous alpha=1.892e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 85 iterations, alpha=5.117e-02, previous alpha=2.777e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=2.651e+01, previous alpha=7.655e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 98 iterations, alpha=4.047e+01, previous alpha=5.428e-05, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 50 iterations, alpha=1.114e+00, previous alpha=1.101e+00, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.518e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 8.560e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=4.194e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.560e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.928e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.996e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.838e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 49 iterations, alpha=4.053e-01, previous alpha=2.026e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=3.443e+01, previous alpha=6.233e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=3.029e+02, previous alpha=5.620e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.516e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.423e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.203e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.057e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.986e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=1.644e+02, previous alpha=4.795e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.398e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.885e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=6.989e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.025e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=5.974e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 7.146e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=5.986e-01, previous alpha=5.794e-01, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 95 iterations, alpha=6.452e-03, previous alpha=5.109e-05, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=1.320e+02, previous alpha=2.196e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=1.341e+02, previous alpha=4.814e-01, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=6.317e+00, previous alpha=1.294e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=5.039e+00, previous alpha=2.347e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=1.089e+02, previous alpha=5.436e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=3.428e+00, previous alpha=4.353e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 82 iterations, alpha=4.512e-01, previous alpha=1.326e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=3.399e-01, previous alpha=3.191e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.111e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 5.960e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=8.165e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=6.783e-01, previous alpha=6.446e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 54 iterations, alpha=7.392e-01, previous alpha=7.033e-01, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=4.789e+01, previous alpha=7.632e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.389e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.212e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.203e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=1.212e-04, previous alpha=1.186e-04, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=1.382e+00, previous alpha=2.492e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.637e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.132e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=5.036e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=4.999e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.161e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=4.953e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 61 iterations, alpha=5.018e-01, previous alpha=4.517e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=2.619e+01, previous alpha=1.428e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=2.008e+01, previous alpha=4.679e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 81 iterations, alpha=4.324e+01, previous alpha=1.695e-06, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=4.698e+01, previous alpha=3.351e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=3.122e+01, previous alpha=3.890e-02, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 80 iterations, alpha=1.653e-01, previous alpha=1.257e-01, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=4.070e+01, previous alpha=9.537e-04, with an active set of 42 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.262e+02, previous alpha=1.591e-01, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.635e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=8.258e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 4.344e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=6.922e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 4.344e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.945e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.856e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=2.480e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.258e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.155e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=5.073e+01, previous alpha=2.127e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=3.744e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 5.268e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=1.741e+02, previous alpha=3.744e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 81 iterations, alpha=1.744e+01, previous alpha=9.304e-02, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=4.901e+01, previous alpha=1.949e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=4.199e+01, previous alpha=4.434e-01, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=2.021e+00, previous alpha=1.919e+00, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.448e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=3.349e+01, previous alpha=2.390e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=2.681e+00, previous alpha=1.422e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=8.046e-02, previous alpha=4.625e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.989e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=6.395e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.820e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=5.613e-01, previous alpha=4.520e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=1.207e+02, previous alpha=9.870e-01, with an active set of 26 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.752e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.584e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.201e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.090e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.068e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=7.223e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.826e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.529e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.424e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=5.120e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=5.081e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=4.653e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=4.187e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.593e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 58 iterations, alpha=8.835e-01, previous alpha=3.829e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=2.185e+02, previous alpha=4.111e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.042e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.034e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.033e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.019e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.593e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.899e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.093e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.714e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.694e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.788e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 73 iterations, alpha=1.034e-01, previous alpha=6.544e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.660e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=1.427e+02, previous alpha=7.641e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.626e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.989e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.585e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.989e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.568e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=2.631e+00, previous alpha=1.009e+00, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=4.385e+01, previous alpha=3.021e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=7.121e+00, previous alpha=9.717e-02, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.673e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.989e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.924e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.829e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.907e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.788e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.841e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.788e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.638e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=2.331e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 6.664e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=2.301e-01, previous alpha=2.224e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=2.988e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.064e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=1.213e+01, previous alpha=2.469e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=5.295e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.941e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=4.154e+01, previous alpha=4.879e-01, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.836e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 4.081e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.037e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.030e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.543e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.484e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.121e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=1.117e+02, previous alpha=4.024e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=9.280e+01, previous alpha=3.532e-01, with an active set of 35 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 90 iterations, alpha=2.522e+01, previous alpha=6.799e-06, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=1.654e+02, previous alpha=6.279e-01, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=1.627e+01, previous alpha=1.608e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=1.092e+02, previous alpha=2.789e-05, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 70 iterations, alpha=8.461e+00, previous alpha=1.500e-01, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.808e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.025e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.099e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 8.025e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.016e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 5.576e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 51 iterations, alpha=8.268e-01, previous alpha=7.353e-01, with an active set of 30 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.683e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.215e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.534e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.464e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.337e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.598e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 51 iterations, alpha=1.298e+00, previous alpha=1.181e+00, with an active set of 24 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=5.684e-01, previous alpha=2.567e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.333e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.028e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\1098071\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=7.522e+01, previous alpha=4.388e-01, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75262252.11746648"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = 10\n",
    "\n",
    "MSE = make_scorer(mean_squared_error)\n",
    "np.mean(cross_val_score(model, data1[features], data1['value'], cv = kf, scoring = MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
