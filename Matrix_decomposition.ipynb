{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything here \n",
    "\n",
    "http://people.duke.edu/~ccc14/sta-663-2017/13A_LinearAlgebra1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Matrix_decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider the following points when choosing the method of matrix decomposition:\n",
    "- all of them approximate the matrix in some way.\n",
    "- some may make the problem easier to solve.\n",
    "- the algorithm.\n",
    "   - Is there an efficient way to find the decomposition? (especially for large matrices. for example SVD is computed more efficiently for large matrices than eigen-decomposition.)\n",
    "   - Can we obtain it with an online algorithm? (updating factorization when new data samples comes in without recomputing all the steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some points on the reason of matrix decompostion.\n",
    "\n",
    "How do you actually solve a large system of linear equations on a computer and how do you actually diagonalize a large matrix (that theory tells you is diagonalizable) on a computer. These are very difficult problems since there is a huge gap between the theoretical results and actual computations. That gap is caused of course by rounding errors on a computer. Loads of books are written on the subject as, needless to say, it's of immense importance. Many factorizations of matrices (e.g., LU and QR) are meant to address such issues. To make computations more robust and more efficient.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lazyprogrammer.me/tutorial-principal-components-analysis-pca/\n",
    "\n",
    "###  PCA\n",
    "PCA finds a matrix Q that, when multiplied by the original data matrix X, returns a linearly transformed data matrix Z, where:\n",
    "\n",
    "**Z = XQ**\n",
    "\n",
    "The interesting thing about PCA is how it chooses Q.\n",
    "\n",
    "PCA reduces dimensionality by moving as much “information” as possible into as few dimensions as possible. The information here is measured by unpredictability, i.e. variance. The end result is that the transformed matrix Z has most of its variance in the first column, less variance in the second column, even less variance in the third column, etc.\n",
    "\n",
    "### Eigenvalues & Eigenvectors\n",
    "when multiply a vector by a matrix, the direction of the vector is changed.\n",
    "\n",
    "Eigenvalues λ and eigenvectors v have the property that, if multiplied by A, a matrix, is the same as multiplying the eigenvector by a constant – the eigenvalue, i.e. the eigenvector does not change direction, it only gets shorter or longer by a factor of λ. In other words:\n",
    "\n",
    "**Av = λv**\n",
    "\n",
    "where A is the matrix, v is the eigenvector and λ the eigenvalue.\n",
    "\n",
    "In the case of PCA, all the eigenvectors from the empirical covariance matrix are lined upsuch that the corresponding λ, eigenvallues, are in descending order. In matrix form, the above can be expressed by:\n",
    "\n",
    "**AV = VΛ **\n",
    "\n",
    "where V is the matrix with eigenvectors as columns, which is orthonormal, and Λ is a diagonal matrix of eigenvalues.\n",
    "\n",
    "### SVD or Diagonalization in finding the eigenpairs\n",
    "\n",
    "The method from textbook – solving a polynomial to get the eigenvalues, plugging the eigenvalues into the eigenvalue equation to get the eigenvectors, etc. doesn’t really translate to computer code.\n",
    "\n",
    "**SVD**\n",
    "- Square the diagonal matrix S, and divide by sum(S) to obtain eigenvalues\n",
    "- Matrix Vt (or U) will contain the eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Λ is a diagonal matrix, there are no correlations in the transformed data. \n",
    "\n",
    "**The variance of each dimension of Z is equal to the eigenvalues.**\n",
    "\n",
    "In addition, because we sorted the eigenvalues in descending order, the first dimension/coluumn of Z has the most variance, the second dimension/coluumn has the second-most variance, etc. So most of the information is kept in the leading dimensions/columns, as promised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (z.shape)\n",
    "# print (z.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACjNJREFUeJzt3F+IZgd9h/Hn29lJ4kartnrR7K7uUoJlsdiEQWIWpCRC\njYq5sRAhofVmL1o1iiCxULzoTS9E9EKEJSqlBkO75kIkNYqai1a7dbJJjburNo3p/nEl20KNBJrd\nrb9ezBTW4M57duecnJkfzwcCO29OTr6EeXLe9513TqoKST39xtwDJE3HwKXGDFxqzMClxgxcaszA\npcYMXGrMwKXGDFxqbMcUJ33Nby3V3j3Lo5/3x9/fOfo5pe3of3ie8/VCFh03SeB79yzzL4/sGf28\nf3TDH4x+Tmk7OlLfHHScT9GlxgxcaszApcYMXGrMwKXGDFxqbFDgSd6e5EdJnkpy39SjJI1jYeBJ\nloDPAHcA+4H3Jtk/9TBJmzfkCv5m4KmqerqqzgMPAndOO0vSGIYEvgs4dcnXp9cf+xVJDiZZTbJ6\n7r/+d6x9kjZhtDfZqupQVa1U1cprf3tprNNK2oQhgZ8BLv1g+e71xyRtcUMC/x5wY5J9Sa4B7gK+\nMu0sSWNY+NtkVXUxyfuBR4Al4PNVdWzyZZI2bdCvi1bVw8DDE2+RNDI/ySY1ZuBSYwYuNWbgUmMG\nLjU2yU0Xf/z9nZPcIPFvT/3T6OcEuGfPgUnOK83NK7jUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFL\njRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41Ngkd1WdylR3P731\nX8+Pfs7vvOma0c8pXSmv4FJjBi41ZuBSYwYuNWbgUmMGLjW2MPAke5J8O8nxJMeS3PtSDJO0eUN+\nDn4R+EhVHU3yCuCxJN+oquMTb5O0SQuv4FV1tqqOrv/5F8AJYNfUwyRt3hW9Bk+yF7gJODLFGEnj\nGvxR1SQvB74MfKiqnvs1f/8gcBDgOnaONlDS1Rt0BU+yzFrcD1TVQ7/umKo6VFUrVbWyzLVjbpR0\nlYa8ix7gc8CJqvrk9JMkjWXIFfwAcA9wW5In1v96x8S7JI1g4WvwqvpHIC/BFkkj85NsUmMGLjVm\n4FJjBi41ZuBSY9vqpotTmeIGicuP/s7o5wS48IdnJzmvevIKLjVm4FJjBi41ZuBSYwYuNWbgUmMG\nLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi415l1VJzLV\n3U+f+4ffneS8v3nHv09yXs3LK7jUmIFLjRm41JiBS40ZuNSYgUuNGbjU2ODAkywleTzJV6ccJGk8\nV3IFvxc4MdUQSeMbFHiS3cA7gfunnSNpTEOv4J8CPgr88nIHJDmYZDXJ6gVeGGWcpM1ZGHiSdwHP\nVtVjGx1XVYeqaqWqVpa5drSBkq7ekCv4AeDdSZ4BHgRuS/LFSVdJGsXCwKvqY1W1u6r2AncB36qq\nuydfJmnT/Dm41NgV/T54VT0KPDrJEkmj8wouNWbgUmMGLjVm4FJjBi415l1Vt5mp7n568u9/f5Lz\nvu6Pn5zkvBrGK7jUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFL\njRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41Jh3VRUw3d1P/+1vbp7kvDf+ydFJztuNV3CpMQOXGjNw\nqTEDlxozcKkxA5caGxR4klclOZzkh0lOJHnL1MMkbd7Qn4N/GvhaVb0nyTXAzgk3SRrJwsCTvBJ4\nK/CnAFV1Hjg/7SxJYxjyFH0fcA74QpLHk9yf5PqJd0kawZDAdwA3A5+tqpuA54H7XnxQkoNJVpOs\nXuCFkWdKuhpDAj8NnK6qI+tfH2Yt+F9RVYeqaqWqVpa5dsyNkq7SwsCr6mfAqSRvWH/oduD4pKsk\njWLou+gfAB5Yfwf9aeB9002SNJZBgVfVE8DKxFskjcxPskmNGbjUmIFLjRm41JiBS40ZuNSYd1XV\npKa6++kzfzX+byzv/cvvjn7OuXkFlxozcKkxA5caM3CpMQOXGjNwqTEDlxozcKkxA5caM3CpMQOX\nGjNwqTEDlxozcKkxA5caM3CpMQOXGjNwqTEDlxozcKkxb7qobWmKGySeue/W0c8JsOuvvzPJeYfw\nCi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41NijwJB9OcizJD5J8Kcl1Uw+TtHkLA0+yC/ggsFJVbwSW\ngLumHiZp84Y+Rd8BvCzJDmAn8NPpJkkay8LAq+oM8AngJHAW+HlVff3FxyU5mGQ1yeoFXhh/qaQr\nNuQp+quBO4F9wA3A9UnufvFxVXWoqlaqamWZa8dfKumKDXmK/jbgJ1V1rqouAA8B03wqX9KohgR+\nErglyc4kAW4HTkw7S9IYhrwGPwIcBo4CT67/M4cm3iVpBIN+H7yqPg58fOItkkbmJ9mkxgxcaszA\npcYMXGrMwKXGvKuqtG6qu58++2fjfy7s4t/986DjvIJLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm4\n1JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS42lqsY/aXIO+I8B\nh74G+M/RB0xnO+3dTlthe+3dCltfX1WvXXTQJIEPlWS1qlZmG3CFttPe7bQVttfe7bTVp+hSYwYu\nNTZ34Idm/vdfqe20dztthe21d9tsnfU1uKRpzX0FlzSh2QJP8vYkP0ryVJL75tqxSJI9Sb6d5HiS\nY0nunXvTEEmWkjye5Ktzb9lIklclOZzkh0lOJHnL3Js2kuTD698HP0jypSTXzb1pI7MEnmQJ+Axw\nB7AfeG+S/XNsGeAi8JGq2g/cAvz5Ft56qXuBE3OPGODTwNeq6veAN7GFNyfZBXwQWKmqNwJLwF3z\nrtrYXFfwNwNPVdXTVXUeeBC4c6YtG6qqs1V1dP3Pv2DtG3DXvKs2lmQ38E7g/rm3bCTJK4G3Ap8D\nqKrzVfXf865aaAfwsiQ7gJ3AT2fes6G5At8FnLrk69Ns8WgAkuwFbgKOzLtkoU8BHwV+OfeQBfYB\n54AvrL+cuD/J9XOPupyqOgN8AjgJnAV+XlVfn3fVxnyTbaAkLwe+DHyoqp6be8/lJHkX8GxVPTb3\nlgF2ADcDn62qm4Dnga38fsyrWXumuQ+4Abg+yd3zrtrYXIGfAfZc8vXu9ce2pCTLrMX9QFU9NPee\nBQ4A707yDGsvfW5L8sV5J13WaeB0Vf3/M6LDrAW/Vb0N+ElVnauqC8BDwK0zb9rQXIF/D7gxyb4k\n17D2RsVXZtqyoSRh7TXiiar65Nx7Fqmqj1XV7qray9p/129V1Za8ylTVz4BTSd6w/tDtwPEZJy1y\nErglyc7174vb2cJvCsLaU6SXXFVdTPJ+4BHW3on8fFUdm2PLAAeAe4Ankzyx/thfVNXDM27q5APA\nA+v/o38aeN/Mey6rqo4kOQwcZe2nK4+zxT/V5ifZpMZ8k01qzMClxgxcaszApcYMXGrMwKXGDFxq\nzMClxv4PjkcoIywatGIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcaec048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "\n",
    "x = np.random.random((100,10)) # generate an N = 100, D = 10 random data matrix\n",
    "\n",
    "# 1. find the principal components which are the linear combiation of the origianl data dimensions. \n",
    "# The full set of principal components has the same number as the number of dimensions in the original dataset\n",
    "# 2. project the data to the span consists of the full set of principal components \n",
    "\n",
    "z = pca.fit_transform(x)\n",
    "\n",
    "# visualize the covariance of the principal components in z\n",
    "plt.imshow(np.cov(z.T))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA summary function - where the input variable pca is a PCA object\n",
    "\n",
    "def pca_summary(pca, standardised_data, out = True):\n",
    "    names = [\"PC\" + str(i) for i in range(1, len(pca.explained_variance_ratio_) +  1)]\n",
    "    \n",
    "    a = list(np.std(pca.transform(standardised_data), axis = 0))\n",
    "    \n",
    "    # the highest eigenvalue indicates the highest variance in the data was observed in the direction of its eigenvector\n",
    "    # The first principal component is calculated such that it accounts for the greatest possible variance in the data set.\n",
    "    b = list(pca.explained_variance_ratio_)\n",
    "    c = [np.sum(pca.explained_variance_ratio_[:i]) for i in range(1, len(pca.explained_variance_ratio_) + 1)]\n",
    "    \n",
    "    columns = pd.MultiIndex.from_tuples([(\"sdev\", \"Standard deviation\"), (\"varprop\", \"Proportion of Variance\"), (\"cumprop\", \"Cumulative Proportion\")])\n",
    "    summary = pd.DataFrame(list(zip(a, b, c)), index = names, columns = columns)\n",
    "    \n",
    "    if out:\n",
    "        print(\"Importance of components:\")\n",
    "#         display(summary)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the first PC preserves the greatest variance in the **projected** data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance of components:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sdev</th>\n",
       "      <th>varprop</th>\n",
       "      <th>cumprop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Standard deviation</th>\n",
       "      <th>Proportion of Variance</th>\n",
       "      <th>Cumulative Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>0.365495</td>\n",
       "      <td>0.163105</td>\n",
       "      <td>0.163105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>0.346078</td>\n",
       "      <td>0.146235</td>\n",
       "      <td>0.309340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC3</th>\n",
       "      <td>0.323277</td>\n",
       "      <td>0.127601</td>\n",
       "      <td>0.436941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC4</th>\n",
       "      <td>0.292866</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.541665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC5</th>\n",
       "      <td>0.282906</td>\n",
       "      <td>0.097721</td>\n",
       "      <td>0.639386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC6</th>\n",
       "      <td>0.270190</td>\n",
       "      <td>0.089134</td>\n",
       "      <td>0.728520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC7</th>\n",
       "      <td>0.255617</td>\n",
       "      <td>0.079778</td>\n",
       "      <td>0.808298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC8</th>\n",
       "      <td>0.240683</td>\n",
       "      <td>0.070729</td>\n",
       "      <td>0.879027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC9</th>\n",
       "      <td>0.226149</td>\n",
       "      <td>0.062444</td>\n",
       "      <td>0.941471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC10</th>\n",
       "      <td>0.218944</td>\n",
       "      <td>0.058529</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sdev                varprop               cumprop\n",
       "     Standard deviation Proportion of Variance Cumulative Proportion\n",
       "PC1            0.365495               0.163105              0.163105\n",
       "PC2            0.346078               0.146235              0.309340\n",
       "PC3            0.323277               0.127601              0.436941\n",
       "PC4            0.292866               0.104723              0.541665\n",
       "PC5            0.282906               0.097721              0.639386\n",
       "PC6            0.270190               0.089134              0.728520\n",
       "PC7            0.255617               0.079778              0.808298\n",
       "PC8            0.240683               0.070729              0.879027\n",
       "PC9            0.226149               0.062444              0.941471\n",
       "PC10           0.218944               0.058529              1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA().fit(x)\n",
    "summary = pca_summary(pca, x)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35139917  0.3446172   0.31539382  0.29653823  0.28780787  0.27672789\n",
      "  0.26668363  0.23607789  0.22374838  0.20809888]\n",
      "0.35139917005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35139917004963794"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (np.std(pca.transform(x), axis = 0))\n",
    "print (np.std(pca.transform(x)[:, 0]))\n",
    "\n",
    "# the first PC preserves the greatest variance in the projected data \n",
    "onedim = PCA(n_components = 1).fit_transform(x)\n",
    "np.std(onedim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the off-diagonals are 0 and that the variances are in decreasing order.\n",
    "Can also confirm that QTQ=I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40394425,  0.58413868,  0.28039281, -0.41928397,  0.12081918,\n",
       "        -0.01159679, -0.2694921 ,  0.02875673, -0.09772216,  0.3787579 ],\n",
       "       [ 0.55492668, -0.45315528,  0.17946532,  0.31313053, -0.3284494 ,\n",
       "        -0.27255056, -0.24114644,  0.17510041,  0.12453115,  0.26451003],\n",
       "       [-0.02374078, -0.04142466, -0.29339907,  0.10728489,  0.43180504,\n",
       "         0.01104663, -0.73780983, -0.16178221,  0.3537723 , -0.13363391],\n",
       "       [ 0.05166975, -0.29592019, -0.10532774, -0.18723837,  0.07257115,\n",
       "         0.73729121,  0.13167153,  0.09590025,  0.3105313 ,  0.4379275 ],\n",
       "       [ 0.1936411 , -0.45128959,  0.02354271, -0.30975952,  0.47318432,\n",
       "        -0.27350621,  0.22771445, -0.50511269, -0.20740137,  0.11669849],\n",
       "       [ 0.06384691,  0.22552556, -0.28174515,  0.63330954,  0.09851148,\n",
       "         0.16239397,  0.03796483, -0.290403  , -0.41983784,  0.4080259 ],\n",
       "       [-0.15134061,  0.10334498,  0.73085314,  0.37359898,  0.23501776,\n",
       "         0.06033835,  0.13908981, -0.25038929,  0.38908475,  0.01978765],\n",
       "       [ 0.155457  ,  0.28508117, -0.41570542,  0.0471406 ,  0.06938059,\n",
       "        -0.38503076,  0.43148787,  0.02349246,  0.58995975,  0.17798898],\n",
       "       [-0.41981704, -0.01605463, -0.02158093, -0.20127444, -0.54158205,\n",
       "        -0.15119388, -0.20715123, -0.519269  ,  0.14673726,  0.3636816 ],\n",
       "       [ 0.51064814,  0.13196306, -0.06809908, -0.01549855, -0.31438115,\n",
       "         0.32547643,  0.07607286, -0.51066901,  0.1144877 , -0.48218127]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the full set of principal components \n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xca4a160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. -0. -0. -0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. -0. -0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0. -0. -0.  0.]\n",
      " [-0.  0.  0.  1.  0.  0. -0.  0.  0. -0.]\n",
      " [-0. -0.  0.  0.  1.  0.  0. -0.  0. -0.]\n",
      " [-0. -0.  0.  0.  0.  1. -0. -0. -0.  0.]\n",
      " [ 0.  0.  0. -0.  0. -0.  1. -0.  0. -0.]\n",
      " [ 0.  0. -0.  0. -0. -0. -0.  1.  0.  0.]\n",
      " [ 0.  0. -0.  0.  0. -0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0. -0. -0.  0. -0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "QTQ = pca.components_.T.dot(pca.components_)\n",
    "plt.imshow(QTQ)\n",
    "plt.show()\n",
    "\n",
    "print (np.around(QTQ, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
